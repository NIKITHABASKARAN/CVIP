# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DFQgQoK_Meor4pPQ3pgich-LO0jti9iU
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
upload=files.upload()
df=pd.read_csv('data.csv')
df.head(7)

#no of rows and columns
df.shape

df.isna().sum

#count of malignant or bening cells
df['diagnosis'].value_counts()

df.dtypes

sns.pairplot(df.iloc[:,1:6])

sns.pairplot(df.iloc[:,1:6],hue='diagnosis')

df.head(5)

df.iloc[:,1:10].corr()

#visulalising correlation
sns.heatmap(df.iloc[:,1:10].corr())

sns.heatmap(df.iloc[:,1:10].corr(),annot=True)

X=df.iloc[:,2:32].values
Y=df.iloc[:,1].values

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.25)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

X_train

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

X_test

#logistic regression
from sklearn.linear_model import LogisticRegression
log=LogisticRegression()
log.fit(X_train,Y_train)

#decision tree
from sklearn.tree import DecisionTreeClassifier
tree=DecisionTreeClassifier(criterion='entropy')
tree.fit(X_train,Y_train)

#random Forest classifier
from sklearn.ensemble import RandomForestClassifier
forest=RandomForestClassifier(n_estimators=10,criterion='entropy')
forest.fit=(X_train,Y_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix
print (cm)
